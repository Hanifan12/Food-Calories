{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Food_Recognition.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-3e9OOqozEO"
      },
      "source": [
        "# Access Dataset\n",
        "tensorflow-dataset food101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc8e0zHFgCHV"
      },
      "source": [
        "## uncomment this line if not using google colab\n",
        "# pip install tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDwCL9ieZ8nC"
      },
      "source": [
        "## import library\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os.path\n",
        "from os import path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMIr36XJqX23"
      },
      "source": [
        "food101_builder = tfds.builder(\"food101\")\n",
        "food101_info = food101_builder.info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seV1bIPo5bS7"
      },
      "source": [
        "def download_food101_dataset():\n",
        "  food101_builder.download_and_prepare(\n",
        "    # download_dir = 'drive/MyDrive/Capstone/Dataset/Food101',\n",
        "    download_config=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yas-EzG2j_I"
      },
      "source": [
        "download_food101_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAVn86_Pzr-t"
      },
      "source": [
        "datasets = food101_builder.as_dataset(\n",
        "    split=None,\n",
        "    batch_size=None,\n",
        "    shuffle_files=False,\n",
        "    read_config=None,\n",
        "    as_supervised=True)\n",
        "\n",
        "train_dataset, val_dataset = datasets[\"train\"], datasets[\"validation\"]\n",
        "assert isinstance(train_dataset, tf.data.Dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGLBUfIZ0xET"
      },
      "source": [
        "## print dataset type\n",
        "ds_train = train_dataset\n",
        "print(ds_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq34SAS9kPsd"
      },
      "source": [
        "## print the metadata\n",
        "ds_info = food101_info\n",
        "print(ds_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6lC_oPEo8oo"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSZAmBdniiqK"
      },
      "source": [
        "def normalize_img(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # Normalize the pixel values\n",
        "    image = image / 255.0\n",
        "    # Resize the image\n",
        "    image = tf.image.resize(image, (224, 224))   # 224 is default\n",
        "    label = tf.expand_dims(label,axis=-1)\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APIfVZ1VgkLK"
      },
      "source": [
        "## normalize train dataset\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "# ds_train = ds_train.cache()\n",
        "# ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip8VWOr9ire_"
      },
      "source": [
        "## normalize validation dataset\n",
        "ds_val = val_dataset\n",
        "ds_val = ds_val.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_val = ds_val.batch(128, drop_remainder=True)\n",
        "# ds_val = ds_val.cache()\n",
        "ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvFtXPypuNLv"
      },
      "source": [
        "## check datatype after normalization\n",
        "print(ds_train)\n",
        "print(ds_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m50g2KQGpEex"
      },
      "source": [
        "# Visualization data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfen2YR4soeK"
      },
      "source": [
        "ds, info = tfds.load(name='food101', \n",
        "                     split='train', \n",
        "                     # data_dir = 'drive/MyDrive/Capstone/Dataset',\n",
        "                     download=False,\n",
        "                     with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdbfilI6c5R_"
      },
      "source": [
        "## show some examples images\n",
        "fig = tfds.show_examples(ds, info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf_YUF52o_oz"
      },
      "source": [
        "# Train Model\n",
        "Pick one manual or trf learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQq9hUAMoVwM"
      },
      "source": [
        "## Manual\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9sJnyoDwgij"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(101, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_prPwmoZn7uz"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKFllrKan14F"
      },
      "source": [
        "model.compile(optimizer='adam' , loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(ds_train, epochs=2, validation_data=ds_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9PGoX1Uoo1M"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9N4GUkelrR9"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "def build_model_mobile():\n",
        "       # constructing the model\n",
        "    model = keras.applications.mobilenet.MobileNet(weights=\"imagenet\", \n",
        "                                                   include_top=False, \n",
        "                                                   input_shape=(224, 224, 3),\n",
        "                                                   pooling='avg')\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Adding custom Layers\n",
        "    x = model.output\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    predictions = Dense(101, activation=\"softmax\")(x)\n",
        "\n",
        "    # creating the final model\n",
        "    model_final = Model(inputs=model.input, outputs=predictions)\n",
        "    \n",
        "    return model_final\n",
        "\n",
        "model_mobile = build_model_mobile()\n",
        "model_mobile.compile(loss=sparse_categorical_crossentropy, optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VgXCim9fz4Q"
      },
      "source": [
        "model_mobile.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArGNtLovxHve"
      },
      "source": [
        "history = model_mobile.fit(ds_train, epochs=1, validation_data=ds_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqanHOb-fHa9"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Os9JP9QnAUd"
      },
      "source": [
        "## make dictionary for label\n",
        "label_path = '/root/tensorflow_datasets/food101/2.0.0/label.labels.txt'\n",
        "dict_label = {}\n",
        "i = 0\n",
        "\n",
        "with open(label_path) as f:\n",
        "    for line in f:\n",
        "      dict_label[int(i)] = line.strip('\\n')\n",
        "      i += 1\n",
        "\n",
        "print(dict_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYkqAw0rfMvS"
      },
      "source": [
        "## upload image for prediction\n",
        "from google.colab import files\n",
        "im = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnJ3xJKg7-4"
      },
      "source": [
        "## making prediction\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "for fn in im.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  pred=model_mobile.predict([images])[0]\n",
        "  print(pred) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbn-9OqejzMf"
      },
      "source": [
        "## get the prediction based on the max value\n",
        "max_value = np.max(pred)\n",
        "print(max_value)\n",
        "predic = np.argmax(pred)\n",
        "print(predic)\n",
        "\n",
        "print('Image = ' + dict_label[predic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBAJrxHDxAck"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Qqns_kHKTa"
      },
      "source": [
        "model = model_mobile\n",
        "model.input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO-7Pq78cEei"
      },
      "source": [
        "from tensorflow import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tfmodel = converter.convert()\n",
        "\n",
        "open('food.h5', 'wb').write(tfmodel)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}